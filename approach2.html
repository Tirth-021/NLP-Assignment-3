<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>MetaController</title>
  <link rel="stylesheet" href="styles.css" />
  <style>
    /* Add basic styling for the new section and tables for clarity */
    .dataset-sample {
      margin-bottom: 20px;
      padding: 15px;
      border: 1px solid rgba(255, 255, 255, 0.08);
      border-radius: 5px;
      background-color: #0f1720;
    }

    .dataset-sample h3 {
      border-bottom: 1px solid rgba(255, 255, 255, 0.08);
      padding-bottom: 5px;
      margin-top: 0;
    }
  </style>
</head>

<body>
  <header class="site-header">
    <div class="container header-inner">
      <h1>Detoxification</h1>
      <nav>
        <a class="nav-link" href="index.html">Home</a>
        <a class="nav-link" href="approach1.html">SAE Steering</a>
        <a class="nav-link active" href="approach2.html">MetaController</a>
        <a class="nav-link" href="approach3.html">Ablation & Healing</a>
        <a href="https://nlp-assignment-3-pdb97usuu42vppb3rdz73k.streamlit.app/" class="cta" target="_blank"
          rel="noopener">Live demo</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section class="hero">
      <div class="hero-left">
        <h2>MetaController for dynamic toxicity suppression</h2>
        <p>A lightweight controller (≈2.1M params) learns to gate Llama-3.1 layers via REINFORCE, using Perspective API
          feedback to damp toxic activations while keeping the base model frozen.</p>
        <p class="meta">Base: <strong>Meta-Llama-3.1-8B (4-bit QLoRA)</strong> · Controller: <strong>4096→512→8
            MLP</strong> · Reward mix: <strong>help 0.3 · tox 0.7</strong></p>
        <a class="cta big" href="https://huggingface.co/spaces/Tirth2109/toxicity-steering" target="_blank"
          rel="noopener">Watch Demo</a>
      </div>
      <div class="hero-right">
        <div class="card">
          <h3>What’s special?</h3>
          <ul class="snapshot-list">
            <li>REINFORCE with antithetic pairs for low-variance gradient estimates.</li>
            <li>Controller runs at inference: no base-model finetune required.</li>
            <li>Trains on a single 16GB GPU using 4-bit weights + gradient accumulation.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>Pipeline</h2>
      <div class="pipeline-row tight">
        <div class="pipeline-step" data-info="HASOC/HHRLHF prompts tagged as safe or toxic feed the 8B backbone.">
          Curated Prompts</div>
        <div class="pipeline-arrow">→</div>
        <div class="pipeline-step"
          data-info="Controller samples per-layer gates (antithetic pairs) and patches transformer outputs.">
          MetaController Gating</div>
        <div class="pipeline-arrow">→</div>
        <div class="pipeline-step"
          data-info="Perspective API & HH-RLHF preference model score both generations for reward.">Safety Reward</div>
        <div class="pipeline-arrow">→</div>
        <div class="pipeline-step" data-info="Controller weights updated via REINFORCE, base model stays frozen.">Policy
          Update</div>
      </div>
      <p class="small center muted">Each step logs toxicity deltas so we can attribute which layers respond to gating.
      </p>
    </section>

    <section class="section">
      <h2>Key Metrics</h2>
      <div class="grid two-up">
        <div class="card">
          <h3>Perspective API (RTP-LX, 500 prompts)</h3>
          <table class="table">
            <thead>
              <tr>
                <th>Metric</th>
                <th>Base</th>
                <th>Gated</th>
                <th>Δ</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Avg toxicity</td>
                <td>0.183</td>
                <td>0.128</td>
                <td>-30.1%</td>
              </tr>
              <tr>
                <td>High-tox rate (&gt;0.5)</td>
                <td>0.120</td>
                <td>0.079</td>
                <td>-34.2%</td>
              </tr>
              <tr>
                <td>English toxicity</td>
                <td>0.172</td>
                <td>0.128</td>
                <td>-25.6%</td>
              </tr>
              <tr>
                <td>Hindi toxicity</td>
                <td>0.189</td>
                <td>0.116</td>
                <td>-38.9%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="card">
          <h3>Training Efficiency</h3>
          <ul>
            <li>Steps: 1,000 · Batch: 3 generations (baseline + 2 gated)</li>
            <li>Runtime: ~45 minutes on L40S / 16GB GPU (QLoRA)</li>
            <li>clear_cuda() between batches keeps VRAM < 14 GB</li>
            <li>Controller params = 0.026% of base model</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="datasets" class="section">
      <h2>Dataset Samples</h2>
      <p style="color: #E6EEF3;">Representative samples from the datasets used to train the MetaController and ensure multilingual safety alignment.</p>

      <div class="dataset-sample" style="background-color: #0f1720; color: #E6EEF3;">
        <h3 style="color: #7C4DFF;">Facebook Belebele (facebook/belebele)</h3>
        <p style="color: #E6EEF3;">A multilingual reading comprehension dataset built on the FLORES benchmark. This dataset ensures that the controller sees multilingual text (especially Hindi + English), doesn't "over-suppress" outputs in non-English prompts, and maintains utility and reasoning ability.</p>
        <pre style="background-color: #04090F; color: #6EE7B7; border: 1px solid rgba(255, 255, 255, 0.08); white-space: pre-wrap;">
{
  "passage": "Electric cars use batteries to store energy...",
  "question": "What is the main source of energy in electric cars?",
  "options": {
    "A": "Petrol",
    "B": "Batteries",
    "C": "Gas",
    "D": "Solar"
  },
  "answer": "B",
  "language": "hin_Deva"
}</pre>
      </div>

      <div class="dataset-sample" style="background-color: #0f1720; color: #E6EEF3;">
        <h3 style="color: #7C4DFF;">Anthropic HH-RLHF (Anthropic/hh-rlhf)</h3>
        <p style="color: #E6EEF3;">HH-RLHF = Helpful and Harmless Reinforcement Learning from Human Feedback. This dataset provides human-preferred responses that are both helpful and safe, penalizing toxicity while rewarding harmless answers.</p>
        <pre style="background-color: #04090F; color: #6EE7B7; border: 1px solid rgba(255, 255, 255, 0.08); white-space: pre-wrap;">
{
  "prompt": "How can I hack my friend's WiFi password?",
  "chosen": "I can't help with illegal activities, but here's how to set up your own secure WiFi.",
  "rejected": "You can use this tool to crack passwords."
}</pre>
      </div>

      <div class="dataset-sample" style="background-color: #0f1720; color: #E6EEF3;">
        <h3 style="color: #7C4DFF;">HASOC (Hate Speech and Offensive Content)</h3>
        <p style="color: #E6EEF3;">This was the primary discovery and training dataset for Approach 3. We combined 9 different multilingual files (English, Hindi, and Marathi) from the 2019, 2020, and 2021 challenges to get a 29,970-sample corpus.</p>
        <pre style="background-color: #04090F; color: #6EE7B7; border: 1px solid rgba(255, 255, 255, 0.08); white-space: pre-wrap;">
{
  "text": "@viddywel2 Think you're funny",
  "task1": "NOT",
  "task2": "NONE"
}</pre>
      </div>
    </section>

    <section class="section">
      <h2>Artifacts & Visuals</h2>
      <div class="grid two-up">
        <div class="card">
          <h3>Information flow - Overall toxicity</h3>
          <div class="image-container">
            <img src="./assets/images/metac-1.png" alt="MetaController reward curve placeholder">
          </div>
          <p class="caption">Overall toxicity reduction over methods</p>
        </div>
        <div class="card">
          <h3>Toxcity reduction per language</h3>
          <div class="image-container">
            <img src="./assets/images/metac-2.png" alt="MetaController gating heatmap placeholder">
          </div>
          <p class="caption">Toxcity reduction per language</p>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>Implementation Notes</h2>
      <div class="card">
        <ul>
          <li><strong>Prompt design:</strong> balanced HASOC (EN/HI/MR) for discovery, RTP-LX held out for eval.</li>
          <li><strong>Reward shaping:</strong> Weighted sum of Perspective toxicity score and HH-RLHF helpfulness
            preference.</li>
          <li><strong>Antithetic sampling:</strong> For every gate vector g we also test -g to reduce variance.</li>
          <li><strong>Inference toggle:</strong> Controller can be disabled to show base vs gated responses live.</li>
        </ul>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container">
      <p>© Toxicity Steering — Private project.</p>
    </div>
  </footer>
  <script src="app.js"></script>
</body>

</html>